# 5장 다중 계층 신경망 (Multi-Layer Neural Network)
작성일 : 20170510
작성자 : 전성욱
TEXT : 텐서플로 첫걸음 (First Contact with TensorFlow)

## 목표
- MINST 손 글씨 숫자를 인식하는 문제 -> 간단한 Deep Learning Neural network을 만든다.
- Deep Learning의 전형적인 예인 합성곱 신경망(CNN:Convolution Neural Network) 사용
- CNN은 1998년 얀 르쿤 등의 몇몇 사람들에 의해 처음 소개
- CNN은 이미지 인식 분야에 성능 좋음

## 중요 개념
- 합성곱 (Convolution)
- 폴링 (Pooling)

## 5.1 합성곱 신경망(CNN:Convolution Neural Network)

특성 : 거의 항상 입력데이터로 이미지를 받는다.
장정 : 신경망(Neural Network)을 효율적으로 구성 가능, 매개변수 수를 줄일 수 있다.

### 데이터 로드
~~~
from tensorflow.examples.tutorials.mnist import input_data
mnist = input_data.read_data_sets('MNIST_data', one_hot=True)
~~~

### 플레이스홀더 정의
~~~
import tensorflow as tf

x = tf.placeholder("float", shape=[None, 784])
y_ = tf.placeholder("float", shape=[None, 10])
~~~

### 입력 데이타를 원래 이미지 구조 재구성
~~~
x_image = tf.reshape(x, [-1,28,28,1])

28X28크기의 2차원 공간의 뉴런들

~~~
[-1,너비,높이,컬러채널]
![그림 5-1 신경망(Neural Network)의 입력 데이터](images/Img5-1.png =300x)
그림 5-1 신경망(Neural Network)의 입력 데이터

### 5.1.1 합성곱(Convolution) 계층
- CNN의 주요 목적 : 테두리, 선, 색 등 이미지의 시각적 특징이나 특성을 감지하는 것이다.
- 이런 부분은 입력 계층과 연결된 은닉 계층(Hiden Layer)에서 처리
- CNN은 입력데이타가 첫 번째 은닉 계층(Hiden Layer)의 뉴런에 완전히 연결(Fully Connected)되어 있지 않다.
- 이미지의 픽셀 정보를 저장하고 있는 입력 뉴런의 작은 일부 영역이 하나의 히든 레이어 뉴런과 연결됩니다

#### 연결
![그림 5-2 은닉 계층(Hiden Layer)의 뉴런과 연결된 입력 데이터](images/Img5-2.png =600x)
그림 5-2 은닉 계층(Hiden Layer)의 뉴런과 연결된 입력 데이터

입력 레이어의 5×5 영역(즉 25개의 뉴런)과 히든 레이어의 각 뉴런 연결

![그림 5-3 윈도우를 이용한 입력 계층과 은닉 계층(Hiden Layer)의 연결](images/Img5-3.png =600x)
그림 5-3 윈도우를 이용한 입력 계층과 은닉 계층(Hiden Layer)의 연결

다시 5X5를 3X3으로 은닉하는 형식으로 다시 설명하자면

![그림 5-3-2 은닉 계층(Hiden Layer)의 뉴런과 연결된 입력 데이터 25x25 to 3x3](images/5-3-2Img.png =800x)
그림 5-3-2 은닉 계층(Hiden Layer)의 뉴런과 연결된 입력 데이터 5x5 to 3x3


#### 개선

합성곱(Convolution Layer)에서 한번에 1개 픽셀 이상 움직이는 것도 가능 

- **스트라이드(Stride)** : 얼마나 움직일지 결정하는 매개변수


이미지 밖으로 윈도우즈가 넘어갈 수 있도록 한다. (좋은 결과를 내기 위해 바깥 테두리를 0으로 채울 수 있다.)

- **패딩(padding)** : 테두리의 크기를 지정하는 매개변수

이 책에서는 스트라이드(Stride), 패딩(padding)는 다루지 않는다. 
스탠포드의 강의 문서 참조 (http://cs231n.github.io/convolutional-networks/)

#### **커널(Kernel)** / **필터(Filter)**
예제에서 입력 계층과 히든 계층의 뉴런을 연결하기 위해서는 앞장의 공식을 따라 5×5 가중치 행렬 **W**와 편향 **b**가 필요합니다.
CNN의 핵심 특징은 가중치 행렬 **W**와 편향 **b**를 히든계층의 __모든 뉴런이 공유__
즉 24X24(576)개의 뉴런이 같은 **W**, **b**를 사용합니다. (완전 연결 신경망(Neural Network)의 경우 W 5X5X24X24(14000)개 필요)

- **커널(Kernel)**  or **필터(Filter)** : 행렬 **W**, 편향(bias) **b**
- **필터(Filter)** : 이미지의 고유한 특성을 찾는데 사용됨

합성곱(Convolution)이 어떻게 작동하는지 감을 잡는데 GIMP메뉴얼의 예제 문서(https://docs.gimp.org/en/plug-in-convmatrix.html) 참조

커널로 **특징 맵(feature map)** or 특성 맵을 만든다.
이는 하나의 행렬 **W**, 편향(bias) **b**으로 하나의 커널(Kernel) 정의 -> 한 종류의 특성만 감지 
그러므로 감지하고 싶은 각 특징에 한 개씩 여러 개의 커널을 사용

![그림 5-4 여러 개의 커널](images/Img5-4.png =600x)
그림 5-4 여러 개의 커널

**합성곱 계층(Convolutional layer)** : 특징 맵들이 모여 있는 것

예제에서는 32개의 커널을 사용할 것임


### 5.1.2 풀링 계층(Pooling Layer)

합성곱(Convolution Layer) 외에 풀링 계층(Pooling Layer)라고 불리우는 레이어가 합성곱(Convolution Layer) 뒤에 따라 오는게 일반적이다.

- **풀링 계층(Pooling Layer)** : 합성곱(Convolution Layer) 출력을 단순하게 압축하고 합성곱(Convolution Layer)이 생산하는 정보를 콤팩트한 버전으로 만들어준다.

![그림 5-5 은닉 계층(Hiden Layer)과 맥스 풀링 유닛](images/Img5-5.png =600x)
그림 5-5 은닉 계층(Hiden Layer)과 맥스 풀링 유닛

정보를 압축하기 위한 다양한 방법 중 **맥스 풀링(Max-Pooling)**을 사용
- **맥스 풀링(Max-Pooling)** : 2X2영역에서 가장 큰 값을 선택해서 정보를 압축

합성곱(Convolution Layer)의 여러 개의 커널로 이루어지므로 따로따로 맥스 풀링을 적용한다.

![그림 5-6 맥스 풀링 계층(Pooling Layer)](images/Img5-6.png =600x)
그림 5-6 맥스 풀링 계층


- 24X24 합성곱(Convolution) 결과 -> 2X2영역 분활 -> 12X12개 크기의 맥스 풀링 계층(Pooling Layer)이 만들어짐
- 합성곱(Convolution Layer)과 달리 데이터가 슬라이딩 윈도우에 의해 생성되는 것이 아니라 타일 처럼 나누어 각각 만들어짐

맥스 풀링은 어떤 특징이 이미지의 여러 곳에 나타날 때, 특징의 정확한 위치 보다는 다른 특징들과의 상대적인 위치가 더 중요하다는 것을 설명해준다.

## 5.2 모델 구현

Minist 예제 문서 (https://www.tensorflow.org/get_started/mnist/pros) 참조


### 가중치 행렬 **W**, 편향(bias) **b** 연관 함수 (Weight Initialization)

우리가 ReLU 뉴런을 사용하고 있기 때문에 "죽은 뉴런"을 피하기 위해 약간 긍정적 인 초기 바이어스로 초기화하는 것이 좋습니다.

~~~
def weight_variable(shape):
  initial = tf.truncated_normal(shape, stddev=0.1)
  return tf.Variable(initial)

def bias_variable(shape):
  initial = tf.constant(0.1, shape=shape)
  return tf.Variable(initial)
~~~
 
- 가중치 행렬은 일종의 random noise로 초기화
- 편향은 작은 양수(0.1)를 갖도록 초기화



### 합성곱(Convolution)과 맥스 풀링을 위한 두개의 함수 (Convolution and Pooling)

스트라이드(Stride) = 1
패딩(Padding) = SAME
폴링(Pooling) = Max-Pooling

~~~
def conv2d(x, W):
  return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')

def max_pool_2x2(x):
  return tf.nn.max_pool(x, ksize=[1, 2, 2, 1],
                        strides=[1, 2, 2, 1], padding='SAME')
~~~

### 첫번째 합성곱(Convolution Layer)과 이를 따르는 풀링 계층(Pooling Layer) 만들기(First Convolutional Layer)

우우크기가 5X5인 32개의 필터 사용 : [5, 5, 1, 32]인 가중치 행렬 W를 저장할 텐서 정의
[가로, 세로, 채널(색상), 특성수]

32개 가중치 행렬 **W**에 대한 편향 **b**을 정의

- 채널 : 1
- 필터 : 32

~~~
W_conv1 = weight_variable([5, 5, 1, 32])
b_conv1 = bias_variable([32])
~~~

ReLU(Rectified Linear Unit) 활성화 한수는 최근 심층 신경만의 은닉 계층(Hiden Layer)에서 거의 기본적으로 사용
ReLU은 max(0,x) : 음수 인 경우 0 그 외의 경우 x 돌려준다.

- 입력 이미지 x_image와 가중치 행렬 **W**를 합성곱(Convolution)하고 여기에 편향 **b**를 하여 ReLU함수에 적용한다.
- 결과 값을 Max-Pooling을 적용한다.

~~~
h_conv1 = tf.nn.relu(conv2d(x_image, W_conv1) + b_conv1)
h_pool1 = max_pool_2x2(h_conv1)
~~~

### 두번째 합성곱 계층(Second Convolutional Layer)

5X5 윈도우에 64개의 필터를 갖는 두번째 합성곱(Convolution Layer)을 만든다.
이전 계층의 출력 값의 크기를(32)를 채널의 수로 넘겨야함

[5, 5, 32, 64] : [가로, 세로, 채널(이전 출력크기), 특성수]

- 채널 : 32
- 필터 : 63

~~~
W_conv2 = weight_variable([5, 5, 32, 64]) 
b_conv2 = bias_variable([64])

h_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2) + b_conv2)
h_pool2 = max_pool_2x2(h_conv2)
~~~


### 빽빽하게 연결된 계층(Densely Connected Layer)

14x14크기의 행렬인 h_pool1에 스트라이드 1로 5X5 위도를 적용하여 합성곱(Convolution Layer)을 만들고,
Max-Pooling까지 거치면 크기가 7X7이 됩니다. (h_pool2)

다음 단계는 앞장에서 했던 것과 비슷하게 마지만 소프트 맥스 계층을 주입하기위해 7X7 출력 값을 완전 연결 계층에 연결합니다.

전체 이미지를 처리하기 위해서는 1024개의 뉴런을 사용하도록 한다.

- 뉴런 : 1024

행렬 가중치 **W** ,편향 **b**을 계산한다. 

텐서의 첫번째 차원은 두번째 합성곱(Convolution Layer)의 7×7 크기의 64개 필터로 부터 왔으며 두번째 파라메타는 우리가 임의로 선택한 뉴런의 갯수(1024)

~~~
W_fc1 = weight_variable([7 * 7 * 64, 1024])
b_fc1 = bias_variable([1024])
~~~


이제 텐서를 벡터로 변환합니다. 이전 장에서 SoftMax 함수는 이미지를 직렬화해서 벡터 형태로 입력을 해야하는 것을 보았습니다. 이를 위해서 가중치 행렬 W_fc1 과 일차원 벡터를 곱하고 바이어스 b_fc1 을 더한 후 ReRU 활성화 함수를 적용합니다

~~~
h_pool2_flat = tf.reshape(h_pool2, [-1, 7*7*64])
h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat, W_fc1) + b_fc1)
~~~

#### 드롭아웃(Dropout)

다음 단계는 드롭아웃(dropout)이라는 기법을 통해 신경망(Neural Network)에서 필요한 파라메타 수를 줄인다.
이는 노드를 삭제하여 입력과 출력 연결을 제거하는 것입니다.
어떤 뉴런을 제거하고 어떤 것을 유지할지는 **무작위**로 결정됩니다. 
뉴런이 제거되거나 그렇지 않을 확률을 코드에서 처리하지 않고 텐서플로에 위임할 것 입니다.

드롭아웃(Dropout)은 모델이 데이터에 오버피팅(overfitting)되는 것을 막아줍니다.

**오버피팅(overfitting)**
  - **오버피팅(overfitting)** : 은닉 계층(Hiden Layer)에 많은 수의 뉴런을 사용하여 상세 모델을 만드는 경우 임의의 노이즈(또는 에러)가 모델에 포함 되는 현상
  - 오버피팅은 입력 데이터의 차원에 비해 더 많은 파라메타를 가지는 모델에서 자주 일어 납니다. 
  - 오퍼피팅은 예측의 성능을 떨어뜨리므로 피하는 것이 좋습니다.

우리 모델에서는 마지막 소프트맥스 레이어 전에 tf.nn.dropout 함수를 사용하여 드롭아웃을 적용합니다. 
그 전에 뉴런이 드롭아웃되지 않을 확률을 저장할 플레이스홀더를 만듭니다.

~~~
keep_prob = tf.placeholder("float") # 드롭아웃되지 않을 확률 저장소
h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob) # 드롭아웃 적용
~~~

### Readout Layer

마지막에 소프트맥스 레이어를 추가

소프트맥스 함수는 입력 이미지가 각 클래스(여기서는 0~9까지 숫자)에 속할 확률을 리턴하며 이 확률의 전체 합은 1이 된다는 것을 기억하십시오. 아래와 같이 소프트 맥스 계층을 만든다.

[1024, 10] : [채널(뉴런수?), 특성수]
- 채널 : 1024 ?
- 필터 : 10

~~~
W_fc2 = weight_variable([1024, 10])
b_fc2 = bias_variable([10])

y_conv=tf.nn.softmax(tf.matmul(h_fc1_drop, W_fc2) + b_fc2)
~~~

## 5.3 모델 훈련 및 평가 (Train and Evaluate the Model)
 
- 이전 장의 예제와 매우 유사하며 다른 점 알고리즘 : '경사 하강법(Gradient Descent) 최적화' -> 'ADAM 최적화'
- 드롭아웃 계층의 확률을 조절하는 추가적인 파라메타 keep_prob 를 feed_dict 인자를 통해 전달함.
- 100번당 한번만 log를 남긴다.
~~~
cross_entropy = tf.reduce_mean(
    tf.nn.softmax_cross_entropy_with_logits(labels=y_, logits=y_conv))
train_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)
correct_prediction = tf.equal(tf.argmax(y_conv,1), tf.argmax(y_,1))
accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))

sess.run(tf.global_variables_initializer())
for i in range(20000):
  batch = mnist.train.next_batch(50)
  if i%100 == 0:
    train_accuracy = accuracy.eval(feed_dict={
        x:batch[0], y_: batch[1], keep_prob: 1.0})
    print("step %d, training accuracy %g"%(i, train_accuracy))
  train_step.run(feed_dict={x: batch[0], y_: batch[1], keep_prob: 0.5})

print("test accuracy %g"%accuracy.eval(feed_dict={
    x: mnist.test.images, y_: mnist.test.labels, keep_prob: 1.0}))
~~~

이 모델은 99.2%의 정확도를 내었습니다.

## 전체 소스
전체소스
~~~
###########################################
# 데이터 로드
from tensorflow.examples.tutorials.mnist import input_data
mnist = input_data.read_data_sets('MNIST_data/', one_hot=True)

###########################################
# 플레이스홀더 정의
import tensorflow as tf

x = tf.placeholder("float", shape=[None, 784])
y_ = tf.placeholder("float", shape=[None, 10])

###########################################
# 입력 데이타를 원래 이미지 구조 재구성
x_image = tf.reshape(x, [-1,28,28,1])

print "x_image="
print x_image

###########################################
# 가중치 행렬 W, 편향(bias) b 초기화 함수 
def weight_variable(shape):
  initial = tf.truncated_normal(shape, stddev=0.1)
  return tf.Variable(initial)

def bias_variable(shape):
  initial = tf.constant(0.1, shape=shape)
  return tf.Variable(initial)

###########################################
# Convolution함수 
def conv2d(x, W):
  return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')
# Max-Pooling함수
def max_pool_2x2(x):
  return tf.nn.max_pool(x, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')

###########################################
# 첫번째 합성곱(Convolution Layer)과 이를 따르는 풀링 계층(Pooling Layer)
W_conv1 = weight_variable([5, 5, 1, 32])
b_conv1 = bias_variable([32])

h_conv1 = tf.nn.relu(conv2d(x_image, W_conv1) + b_conv1)
h_pool1 = max_pool_2x2(h_conv1)

###########################################
# 두번째 합성곱(Convolution Layer)
W_conv2 = weight_variable([5, 5, 32, 64])
b_conv2 = bias_variable([64])

h_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2) + b_conv2)
h_pool2 = max_pool_2x2(h_conv2)

###########################################
# Densely Connected Layer
W_fc1 = weight_variable([7 * 7 * 64, 1024])
b_fc1 = bias_variable([1024])

h_pool2_flat = tf.reshape(h_pool2, [-1, 7*7*64])
h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat, W_fc1) + b_fc1)

###########################################
# 드롭아웃
keep_prob = tf.placeholder("float")
h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob)

###########################################
# Readout Layer
W_fc2 = weight_variable([1024, 10])
b_fc2 = bias_variable([10])

y_conv=tf.nn.softmax(tf.matmul(h_fc1_drop, W_fc2) + b_fc2)

###########################################
# 모델 훈련 및 평가
cross_entropy = -tf.reduce_sum(y_*tf.log(y_conv))
train_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)
correct_prediction = tf.equal(tf.argmax(y_conv,1), tf.argmax(y_,1))
accuracy = tf.reduce_mean(tf.cast(correct_prediction, "float"))

sess = tf.Session()

sess.run(tf.initialize_all_variables())

for i in range(2000):
   batch = mnist.train.next_batch(50)
   if i%10 == 0:
     train_accuracy = sess.run( accuracy, feed_dict={ x:batch[0], y_: batch[1], keep_prob: 1.0})
     print("step %d, training accuracy %g"%(i, train_accuracy))
   sess.run(train_step,feed_dict={x: batch[0], y_: batch[1], keep_prob: 0.5})

print("test accuracy %g"% sess.run(accuracy, feed_dict={
       x: mnist.test.images, y_: mnist.test.labels, keep_prob: 1.0}))
~~~

### 참조 
문서 : Tensorflow Site문서 (https://www.tensorflow.org/get_started/mnist/pros)
소스코드 : tensorflow github source내 예제소스(https://github.com/tensorflow/tensorflow/tree/master/tensorflow/examples/tutorials/mnist) : mnist_deep.py

### 참조 자료 (강재호님 추천)
[Bias vs. Variance](http://gnujoow.github.io/ml/2016/09/01/ML8-Bias-vs-Variance/)
[MNIST Demos on Yann LeCun's website](http://yann.lecun.com/exdb/lenet/)
[CS231n Convolutional Neural Networks for Visual Recognition](http://cs231n.github.io/convolutional-networks/)
[HANDWRITTEN DIGITS RECOGNITION USING DEEP LEARNING](https://faisalorakzai.wordpress.com/2016/06/01/handwritten-digits-recognition-using-deep-learning/)
[What is the difference between convolutional neural networks, restricted Boltzmann machines, and auto-encoders?](https://stats.stackexchange.com/questions/114385/what-is-the-difference-between-convolutional-neural-networks-restricted-boltzma)





